<!DOCTYPE html>
<html lang="en">
	<head>
    	<meta charset="utf-8">
    	<title>Brain Algorithms Reading Group, Spring, 2023</title>
    	<meta name="viewport" content="width=device-width, initial-scale=1.0">
    	<meta name="description" content="">
    	<meta name="author" content="">

    	<!-- Le styles -->
    	<link href="./bootstrapFlatly.min.css" rel="stylesheet">
    	<style>
      	body {
        	/*padding-top: 60px;  60px to make the container go all the way to the bottom of the topbar */
      	}
    	</style>
    	<link href="./bootstrap-responsive.min.css" rel="stylesheet">
    	<link href="./main.css" rel="stylesheet">
	</head>
	<body>
	<div class="container">
	<div class="row-fluid">
	  <h3>Brain Algorithms Reading Group, Spring, 2023</h3>
   </div>
	<div class="row-fluid voffset1">
      	<span class="icon-time"></span><strong>Time:</strong> Tuesdays, 10:30 AM–12:30PM (First meeting 2/7)
	</div>
	 <div class="row-fluid voffset1">
	  <span class="icon-map-marker"></span><strong>Location:</strong> Room G451 (Feb 7), Room G631 (Feb 14 and later) <br>
	  
	</div>
	 <div class="row-fluid voffset1">
	  <span class="icon-envelope"></span><strong>Organizers:</strong>Nancy Lynch, Brabeeba Wang and Sabrina Drammis<br>
	</div>
	<ul>
		<li>
			<a href="http://www.cameronmusco.com/neuralReadingGroup/">Reading group website in 2019</a>
		</li>
		<li>
			<a href="https://brabeeba.github.io/neuralReadingGroup/index.html">Reading group website in 2020</a>
		</li>
	</ul>

<div class="row-fluid voffset1">
	<div class="col-md-10 colp-lg-8" >
   		<img src="./triple.png" class="img-rounded img-responsive" alt="my photo">
</div>
  <div class="row voffset1">
    <div class="col-md-12">
      <section id="publications">
      	<h3>Introduction</h3>
      	<p>
      		This reading group will cover recent papers in the research area of 
Brain Algorithms.  This area studies specific brain mechanisms for 
important brain tasks such as memory and recall, focus and attention, 
decision-making, intuitive and
symbolic thinking, and prediction. This involves representing complex 
concepts in terms of patterns of neural firing, and using those 
representations to make decisions or produce other types of output. 
The area studies these mechanisms by modeling them formally as 
abstract distributed algorithms, and analyzing them using methods from 
analysis of algorithms.</p>

<p>Topics of interest this term may include recognition of hierarchically 
structured concepts, novelty detection, and neural assemblies. We will 
also study some mechanisms that are involve in interaction with the 
real world. Thus, we will consider representing notions such as 
position and motion, and using the representations to perform tasks 
such as orientation and navigation.</p>

<p>We will also consider general issues involved in modeling brain 
mechanisms, such as composition, abstraction, and general learning 
rules.
      	</p>
      	<!-- <h3>Background reading/watching</h3>
      	<ul>
      		<li>
      			<a href="https://b-ok.cc/book/2477222/4a05ed">Principles of Neural Science</a>
      		</li>
      		<li>
      			<a href="https://nancysbraintalks.mit.edu/">Nancy Kanwisher online course</a>
      		</li>
      		<li>
      			<a href="https://computationandbrain.github.io/about/">Christos Papadimitriou on-line course ("Computation and the Brain")</a>
      		</li>
      		<li>
      			<a href="http://cseweb.ucsd.edu/~dasgupta/254-neural-ul/index.html">Sanjoy Dasgupta’s course (“Neurally-inspired unsupervised learning")</a>
      		</li>
      		<li>
      			<a href="https://www.frontiersin.org/research-topics/39/spike-timing-dependent-plasticity">Reviews on Spike-timing dependent plasticity</a>
      		</li>
      	</ul> -->


        <h3>(Tentative) Schedule</h3>
		
		<p>(2/7) Overview of our works on SNN and planning:  Nancy Lynch
				<ul>
					<li>
						<a href="./Brain_Algorithms.pdf">Brain algorithms overview</a>
					</li>
					<li>
						<a href="./Lecture 1.pptx">Slides</a>
					</li>
					<li>
						<a href="https://arxiv.org/pdf/1904.12591.pdf">Nancy Lynch, Cameron Musco, and Merav Parter. Winner-Take-All 
Computation in Spiking Neural Networks. arXiv:1904.12591, April 2019.</a>
					</li>
					<li>
						<a href="https://arxiv.org/pdf/1909.04559.pdf">Nancy Lynch and Frederik Mallmann-Trenn. Learning Hierarchically 
Structured Concepts. Neural Networks, 143:798-817, November 2021</a>
					</li>
					<li>
						<a href="https://arxiv.org/pdf/1808.03884.pdf">
Nancy Lynch and Cameron Musco. A Basic Compositional Model for Spiking 
Neural Networks. In Nils Jansen, Marielle Stoelinga, Petra van den 
Bos, editors, A Journey from Process Algebra via Timed Automata to 
Model Learning: Essays Dedicated to Frits Vaandrager on the Occasion 
of His 60th Birthday, September 2022, volume 13560 of Lecture Notes in 
Computer Science, Springer, 2022.</a>
					</li>
				</ul>
			
		</p>

		<p>(2/14) Navlakha's work: Brabeeba Wang</p>
		<ul>
				<li>
					<a href="./Navlakha 02142023.pdf">Slides</a>
				</li>
					<li>
						<a href="https://www.biorxiv.org/content/biorxiv/early/2017/08/25/180471.full.pdf">A neural algorithm for a fundamental computing problem. S Dasgupta, CF Stevens, S Navlakha. Science, 2017</a>
					</li>
					<li>
						<a href="https://www.pnas.org/doi/epdf/10.1073/pnas.1915252117">Habituation as a neural algorithm for online odor discrimination. Y Shen, S Dasgupta, S Navlakha. Proceedings of the National Academy of Sciences, 2020.</a>
					</li>
					<li>
						<a href="https://www.pnas.org/doi/full/10.1073/pnas.1814448115">A neural data structure for novelty detection. S Dasgupta, TC Sheehan, CF Stevens, S Navlakha. Proceedings of the National Academy of Sciences, 2018</a>
					</li>
				</ul>
		
		<p>(2/21) Papadimitiou and Vempala's work: Sabrina Drammis
			<ul>
				<li>
					<a href="./Assembly-Calculus.pdf">Slides</a>
				</li>
				<li>
					<a href="https://www.pnas.org/doi/epdf/10.1073/pnas.2001893117">Brain computation by assemblies of neurons. Christos H. Papadimitriou, Santosh S. Vempala, Daniel Mitropolsky, Michael Collins, and Wolfgang Maass. Proceedings of the National Academy of Sciences, 2020.</a>
				</li>
				<li>
					<a href="https://arxiv.org/pdf/2206.13217.pdf">Center-Embedding and Constituency in the Brain and a New Characterization of Context-Free Languages. Daniel Mitropolsky, Adiba Ejaz, Mirah Shi, Mihalis Yannakakis, Christos H. Papadimitriou. 2022.</a>
				</li>
			</ul>
		</p>
		
		<p>(2/28) Overview on rate populational models: Keith Murray
			<ul>
				
				<li>
					<a href="https://docs.google.com/presentation/d/1VgpC-bjfZZSU-C_ZWxcuKSsoahftoEhn5xnJXDqt5MI/edit#slide=id.p">Slides</a>
				</li>
				<li>
					<a href="https://direct.mit.edu/neco/article/25/3/626/7854/Opening-the-Black-Box-Low-Dimensional-Dynamics-in">Opening the Black Box: Low-dimensional dynamics in high-dimensional recurrent neural networks, Sussillo and Barak. Neural Computation, 2013.</a>
				</li>
				<li>
					<a href="https://www.nature.com/articles/nature12742">Context-dependent computation by recurrent dynamics in prefrontal cortex. Valerio Mante, David Sussillo, Krishna V. Shenoy & William T. Newsome. Nature, 2013.</a>
				</li>
				<li>
					<a href="https://boulderschool.yale.edu/sites/default/files/files/DayanAbbott.pdf">Theoretical Neuroscience - Chapter 7: Network Models, Dayan and Abbott (optional)</a>

				</li>
			</ul>
		</p>
		<p>(3/7) Learning successor representation: Brabeeba Wang
			<ul>
				<li>
					<a href="https://www.nature.com/articles/nn.4650">The hippocampus as a predictive map. Kimberly L Stachenfeld, Matthew M Botvinick and Samuel J Gershman. Nature Neuroscience. (20)1643–1653, 2017.</a>
				</li>
				<li>
					<a href="https://www.biorxiv.org/content/biorxiv/early/2022/05/19/2022.05.18.492543.full.pdf">Neural learning rules for generating flexible predictions and computing the successor representation. C Fang, D Aronov, LF Abbott, E Mackevicius. bioRxiv, 2022.</a>
				</li>
				
			</ul>
		</p>


		<p>(3/14) Computing through neural dynamics and geometry: Keith Murray
			<ul>
				<li>
					<a href="https://docs.google.com/presentation/d/1-Xe7YbvIJQnOhzX05o8eBLVOoxaQd-kvqnbIyQSuajI/edit#slide=id.p">Slides</a>
				</li>
					<li>
					<a href="https://www.biorxiv.org/content/10.1101/2022.08.15.503870v1.abstract">Flexible multitask computation in recurrent networks utilizes shared dynamical motifs. Laura Driscoll,  Krishna Shenoy,  David Sussillo. 2022.</a>
				</li>
				<li>
					<a href="https://www.biorxiv.org/content/10.1101/2022.10.10.511448v1.abstract">Neural dynamics and geometry for transitive inference. Kenneth Kay, Xue-Xin Wei,  Ramin Khajeh,  Manuel Beiran,  Christopher J. Cueva,  Greg Jensen,  Vincent P. Ferrera, L.F. Abbott. 2022.</a>
				</li>
			</ul>
			
		</p>
<!-- 
		<p>(3/14) Learning and computing at the same time: Brabeeba Wang
			<li>
				<a href="https://www.sciencedirect.com/science/article/pii/S0092867419311705">Continual learning in a multi-layer network of an electric fish</a>
			</li>
			<li>
				<a href="https://www.biorxiv.org/content/10.1101/2022.10.31.514538v1.full.pdf">A Biophysical Basis for Learning and Transmitting Sensory Predictions</a>
			</li>
		</p> -->


		<p>(3/21) Dopamine for causal inference: Sabrina Drammis
			<ul>
				<li>
					<a href="./Jeong et al.pdf">
Mesolimbic dopamine release conveys causal associations. Huijeong Jeong, Annie Taylor, Joseph R Floeder, Martin Lohmann, Stefan Mihalas, Brenda Wu, Mingkang Zhou, Dennis A Burke, Vijay Mohan K Namboodiri. Science. 2022.</a>
				</li>
			</ul>

		</p>
		
		
		<p>(3/28) Spring break
		</p>
		
		
			
		<p>(4/4) Break

		</p>

			<p>(4/11) Break
					</p>
		<p>(4/18) Comparison of different dopamine hypothesis: Sabrina Drammis, Brabeeba Wang
			<ul>
				<li>
					<a href="./Comparison of dopamine hypothesis 04182023.pdf">Slides</a>
				</li>
				<li>
					<a href="./Jeong et al.pdf">
Mesolimbic dopamine release conveys causal associations. Huijeong Jeong, Annie Taylor, Joseph R Floeder, Martin Lohmann, Stefan Mihalas, Brenda Wu, Mingkang Zhou, Dennis A Burke, Vijay Mohan K Namboodiri. Science. 2022.</a>
				</li>
				<li>
					<a href="https://www.nature.com/articles/s41593-022-01109-2">A gradual temporal shift of dopamine responses mirrors the progression of temporal difference error in machine learning. Ryunosuke Amo, Sara Matias, Akihiro Yamanaka, Kenji F. Tanaka, Naoshige Uchida and Mitsuko Watabe-Uchida. Nature Neurosience. 2022.</a>
				</li>
				<li>
					<a href="https://www.cell.com/cell/pdf/S0092-8674(20)31530-0.pdf">A Unified Framework for Dopamine Signals across
Timescales. HyungGoo R. Kim, Athar N. Malik, John G. Mikhael, Pol Bech, Iku Tsutsui-Kimura, Fangmiao Sun,
Yajun Zhang, Yulong Li, Mitsuko Watabe-Uchida, Samuel J. Gershman, and Naoshige Uchida. Cell. 2020.</a>
				</li>
			</ul>
		</p>

		
	
		<p>(4/25) Learning and computing at the same time: Brabeeba Wang
			<li>
				<a href="https://www.sciencedirect.com/science/article/pii/S0092867419311705">Continual learning in a multi-layer network of an electric fish</a>
			</li>
			<li>
				<a href="https://www.biorxiv.org/content/10.1101/2022.10.31.514538v1.full.pdf">A Biophysical Basis for Learning and Transmitting Sensory Predictions</a>
			</li>
		</p> 
		<p>(5/2) Connectome based theory in Drosophila: Brabeeba Wang
			<li>
				<a href="https://www.sciencedirect.com/science/article/pii/S0896627320306139">The Neuroanatomical Ultrastructure and Function of a Biological Ring Attractor. Daniel B. Turner-Evans, Kristopher T. Jensen, Saba Ali, Tyler Paterson, Arlo Sheridan, Robert P. Ray, Tanya Wolff, J. Scott Lauritzen, Gerald M. Rubin, Davi D. Bock, Vivek Jayaraman. Neuron. 2020. </a>
			</li>
			<li>
				<a href="https://www.biorxiv.org/content/10.1101/2022.05.23.493052v1.abstract">Accurate angular integration with only a handful of neurons. Marcella Noorman, Brad K Hulse,  Vivek Jayaraman,  Sandro Romani,  Ann M Hermundstad. BioRxiv. 2022.</a>
			</li>

			<li>
				<a href="https://www.biorxiv.org/content/10.1101/2022.11.10.516026v1">Converting an allocentric goal into an egocentric steering signal. Peter Mussells Pires, L.F. Abbott,  Gaby Maimon. BioRxiv. 2022.</a>
			</li>

			<li>
				<a href="https://www.nature.com/articles/s41586-021-04067-0">Building an allocentric travelling direction signal via vector computation. Cheng Lyu, L. F. Abbott, Gaby Maimon. Nature. 2021.</a>
			</li>

		</p>
		<p>(5/9)  Symbolic and intuitive structures: Nancy Lynch
			<ul>
				<li>
					<a href="https://arxiv.org/abs/2206.02932">Symbolic Knowledge Structures and Intuitive Knowledge Structures</a>
				</li>
			</ul>
		</p>
		<p>(5/16) Topic TBD: Speaker TBD</p>
			<a href="https://accessibility.mit.edu/">Accessibility</a>
		
	<!--	<h4><strong>Unscheduled but need/want to fit in somewhere</strong></h4>
		<p>
			<ul>
				<li><a href="https://igi-web.tugraz.at/people/maass/psfiles/154.pdf">What Can a Neuron Learn with Spike-Timing-Dependent Plasticity?</a> Brabeeba might be interested in presenting.
			<li><a href="https://arxiv.org/abs/1803.09574">Long short-term memory and learning-to-learn in networks of spiking neurons</a>, Quanquan?</li>
			<li><a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004347">Decreasing-Rate Pruning Optimizes the Construction of Efficient and Robust Distributed Networks</a>, Navlakha, Barth, Bar-Joseph.</li>
			<li>Other learning papers people are interested in?</li>
			</ul>
		</p>-->
	  </section>
	</div>
</div>
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="./jquery-1.11.1.min.js"></script>
    <script src="./bootstrap.min.js"></script>

</div>
</body>
</html>